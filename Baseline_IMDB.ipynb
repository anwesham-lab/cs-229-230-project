{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anwesham-lab/cs-229-230-project/blob/main/Baseline_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs2kzz-NTCqJ"
      },
      "source": [
        "# Install Necessary Packages \n",
        "- datasets\n",
        "- tokenizers\n",
        "- transformers\n",
        "\n",
        "From HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "A7wxEGLMiHmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukKgt0AmTB5O"
      },
      "outputs": [],
      "source": [
        "!pip install datasets tokenizers wandb seqeval\n",
        "!pip install -qqq git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXNKtWnAWlnu"
      },
      "source": [
        "Run all necessary imports at the top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhQEyWDMWqkX"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import AutoTokenizer, DataCollatorForTokenClassification, AutoModelForTokenClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "import wandb\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEC54mccJCGz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JImbwfnMJEHH"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/My\\ Drive/230\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN-p84N6Ue_a"
      },
      "source": [
        "# Load in the Dataset\n",
        "\n",
        "Try the IMDB dataset that's on huggingface. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('imdb', 'Lucylulu--imdb')"
      ],
      "metadata": {
        "id": "EGpbQlQ2W_3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][2]"
      ],
      "metadata": {
        "id": "WhC2RIekleom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['validation'][4888]"
      ],
      "metadata": {
        "id": "q0eju4TnlhOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['test'][904]"
      ],
      "metadata": {
        "id": "YQqMB3r1lk_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset['train']), len(dataset['validation']), len(dataset['test']))"
      ],
      "metadata": {
        "id": "pj_hzhpPln_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQHPYn81e8Vt"
      },
      "source": [
        "# Tokenization and Labeling Scheme\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR_GfZRSB037"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
        "\n",
        "def tokenize(all_samples_per_split):\n",
        "  tokenized_samples = tokenizer.batch_encode_plus(all_samples_per_split[\"text\"], is_split_into_words=False, truncation=True, max_length=512)\n",
        "  return tokenized_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad3IPJ07JL5v"
      },
      "outputs": [],
      "source": [
        "token_data = dataset.map(tokenize, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRKIR9XsZlw1"
      },
      "source": [
        "Verify the data returns as expected with attention mask in triple with the input and token type IDs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElLnYPmEZZRy"
      },
      "outputs": [],
      "source": [
        "token_data[\"test\"][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JpMVjWmaKRC"
      },
      "source": [
        "# Padding\n",
        "\n",
        "For all samples, X, where X not sample A, the length of X should equal the length of A for regular input handling with the attention model. Use data collator (huggingface implementation of collate_fn from pytorch, but a lil more portable imo). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiIp4U50Z2cw"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBtA_KCccsKi"
      },
      "source": [
        "# Set Up Weights and Biases Logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWGLGuXzrfWb"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIh0OruxsTq2"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"trial_imdb\", entity=\"anwesham\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewumt530si6t"
      },
      "source": [
        "#Evaluation Setup\n",
        "\n",
        "Want to evaluate the precision, recall, f1, and general accuracy. We want both the f1 and the accuracy because generally, we'll want to gauge not only how impactful false positives and negatives are, but the general rate of correct predictions as well. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEtO0IsEtUXA"
      },
      "source": [
        "#Initialize the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GudMWJjtXS5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-cased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbmr0qSrtax_"
      },
      "source": [
        "#Define the training arguments and trainer "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "def compute_metrics(p):    \n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1} "
      ],
      "metadata": {
        "id": "rvhzaevzd0u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wiUrQHst0Mi"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./distilbert_imdb\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=7,\n",
        "    logging_strategy='steps',\n",
        "    logging_steps = 500,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to = 'wandb'\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset= token_data[\"train\"],\n",
        "    eval_dataset= token_data[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=1, early_stopping_threshold=0.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU9V0BknzYZl"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VQt6BQNzCLT"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha0xrYC9qhYP"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"distilbert_imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-m1rpjM7-HD"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Baseline_IMDB.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}